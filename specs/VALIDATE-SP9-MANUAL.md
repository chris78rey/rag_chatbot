# Validaci√≥n Manual de Subproyecto 9 - Observabilidad

## ‚ö†Ô∏è Requisitos Previos

Antes de validar, aseg√∫rate de que:
1. Docker y Docker Compose est√°n instalados
2. Est√°s en el directorio ra√≠z del proyecto: `G:\zed_projects\raf_chatbot`
3. Las variables de entorno est√°n configuradas (ver `.env`)

## üöÄ Paso 1: Iniciar los Servicios con Docker Compose

```powershell
# En PowerShell, desde G:\zed_projects\raf_chatbot
cd G:\zed_projects\raf_chatbot

# Iniciar todos los servicios (qdrant, redis, api, nginx, etc.)
docker compose -f deploy/compose/docker-compose.yml up -d
```

**Esperar 15-20 segundos** a que el API se inicie correctamente.

Verificar que est√° corriendo:
```powershell
# Ver logs del API
docker compose -f deploy/compose/docker-compose.yml logs api

# Deber√≠a ver algo como:
# INFO:     Uvicorn running on http://0.0.0.0:8000
```

## ‚úÖ Paso 2: Verificar que /metrics est√° disponible

```powershell
# Test 1: Endpoint responde
curl -s http://localhost:8000/metrics | ConvertFrom-Json | Format-Table

# Deber√≠a retornar JSON con estos campos:
# - requests_total
# - errors_total
# - cache_hits_total
# - rate_limited_total
# - avg_latency_ms
# - p95_latency_ms
# - latency_samples
```

**Resultado esperado:**
```json
{
  "requests_total": 0,
  "errors_total": 0,
  "cache_hits_total": 0,
  "rate_limited_total": 0,
  "avg_latency_ms": 0.0,
  "p95_latency_ms": 0.0,
  "latency_samples": 0
}
```

## üîÑ Paso 3: Hacer Consultas para Incrementar M√©tricas

```powershell
# Hacer 5 consultas al endpoint /query
for ($i = 1; $i -le 5; $i++) {
    $body = @{
        rag_id = "test"
        question = "¬øQu√© es FastAPI?"
        top_k = 5
    } | ConvertTo-Json
    
    curl -X POST http://localhost:8000/query `
        -H "Content-Type: application/json" `
        -d $body -v
    
    Write-Host "Query $i completado"
    Start-Sleep -Milliseconds 500
}
```

## üìä Paso 4: Verificar que las M√©tricas Cambiaron

```powershell
# Test 2: Obtener m√©tricas actuales
curl -s http://localhost:8000/metrics | ConvertFrom-Json | Format-Table

# Deber√≠a mostrar:
# ‚úì requests_total: 5 (o mayor)
# ‚úì avg_latency_ms: > 0 (un n√∫mero positivo)
# ‚úì latency_samples: 5 (o mayor)
```

**Resultado esperado despu√©s de 5 queries:**
```json
{
  "requests_total": 5,
  "errors_total": 0,
  "cache_hits_total": 0,
  "rate_limited_total": 0,
  "avg_latency_ms": 234.5,
  "p95_latency_ms": 512.3,
  "latency_samples": 5
}
```

## üß™ Paso 5: Ejecutar Script de Validaci√≥n Autom√°tica

Una vez que el API est√© corriendo:

```powershell
cd G:\zed_projects\raf_chatbot
python scripts/validate-sp9.py
```

Deber√≠a ver:
```
============================================================
VALIDACI√ìN DE SUBPROYECTO 9 - OBSERVABILIDAD
============================================================

[TEST 1] Verificar que /metrics est√° disponible...
‚úì Endpoint /metrics respondi√≥ con 200

[TEST 2] Verificar schema de m√©tricas...
‚úì Schema correcto. Campos presentes: requests_total, errors_total, ...

[TEST 3] Verificar estado inicial de m√©tricas...
‚úì requests_total inicialmente es 0

[TEST 4] Verificar que requests_total incrementa...
‚úì requests_total increment√≥ de 0 a 5

[TEST 5] Verificar registro de latencias...
‚úì Se registraron 5 muestras de latencia
  Latencia promedio: 234.5ms

[TEST 6] Verificar tipos de datos...
‚úì requests_total: int = 5
‚úì errors_total: int = 0
...

============================================================
RESUMEN DE PRUEBAS
============================================================
‚úì PASS: Endpoint /metrics existe
‚úì PASS: Schema de m√©tricas correcto
‚úì PASS: Estado inicial de m√©tricas
‚úì PASS: Incremento de requests_total
‚úì PASS: Registro de latencias
‚úì PASS: Tipos de datos correctos

Total: 6 pasadas, 0 fallidas
```

## üõë Paso 6: Detener los Servicios

Cuando termines la validaci√≥n:

```powershell
# Detener todos los servicios
docker compose -f deploy/compose/docker-compose.yml down

# (Opcional) Limpiar vol√∫menes
docker compose -f deploy/compose/docker-compose.yml down -v
```

## ‚ú® Checklist de Validaci√≥n

Despu√©s de completar los pasos, marca lo siguiente:

- [ ] `/metrics` retorna status 200
- [ ] Schema contiene 7 campos requeridos
- [ ] `requests_total` es 0 al inicio
- [ ] `requests_total` incrementa despu√©s de queries
- [ ] `avg_latency_ms` > 0 (no 0)
- [ ] `latency_samples` > 0 
- [ ] Script `validate-sp9.py` pasa todos los tests

## üêõ Troubleshooting

### Error: "No se puede conectar a localhost:8000"
- Verificar que docker-compose est√© corriendo: `docker compose ps`
- Esperar m√°s tiempo (puede tomar 20-30 segundos)
- Verificar logs: `docker compose logs api`

### Error: "requests_total siempre es 0"
- Verificar que el query endpoint est√© instrumentado
- Revisar que `observability.py` est√° importado en `query.py`
- Verificar logs del API

### Error: "latency_samples es 0"
- Confirmar que se est√°n haciendo queries exitosas
- Verificar que Timer est√° siendo usado correctamente
- Revisar que `record_latency()` se llama

### Error: "Campo faltante en schema"
- Verificar que `MetricsResponse` tiene todos los campos
- Revisar `routes/metrics.py`
- Verificar que `get_snapshot()` retorna todos los campos

## üìñ Informaci√≥n Adicional

- **Documentaci√≥n completa**: `docs/observability.md`
- **C√≥digo fuente**: `services/api/app/observability.py`
- **Endpoint**: `services/api/app/routes/metrics.py`
- **Instrumentaci√≥n**: `services/api/app/routes/query.py`

## üéØ Pr√≥ximos Pasos

Una vez validado SP9:
1. Documentar resultados
2. Proceder con Subproyecto 10 (Gesti√≥n de estado)

---

**Nota**: Las m√©tricas se pierden al reiniciar el contenedor (comportamiento esperado en MVP).