# ğŸ“‹ RAF Chatbot â€” Ingest Service

## Overview

The Ingest Service is responsible for processing and indexing documents into the RAG system.

Documents flow through:
1. **CLI** â€” User submits documents via command line
2. **Queue** â€” Redis-based job queue (non-blocking)
3. **Worker** â€” Async worker processes documents
4. **Qdrant** â€” Vector database stores embeddings

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User: Copy file to data/sources/<rag_id>/incoming  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CLI (services/ingest/cli.py)                       â”‚
â”‚  - Validates file                                   â”‚
â”‚  - Creates job                                      â”‚
â”‚  - Submits to Redis queue                           â”‚
â”‚  - Returns job_id                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Redis Queue (rag:ingest:queue)                     â”‚
â”‚  - Stores job messages (JSON)                       â”‚
â”‚  - Persists state for reliability                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Worker (services/ingest/worker.py)                 â”‚
â”‚  - Polls Redis queue                               â”‚
â”‚  - Loads document (PDF/TXT/MD/DOCX)                 â”‚
â”‚  - Splits into chunks                              â”‚
â”‚  - Generates embeddings                            â”‚
â”‚  - Upserts to Qdrant                               â”‚
â”‚  - Updates job status                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  File Movement & Status                             â”‚
â”‚  - Success: processed/                              â”‚
â”‚  - Failure: failed/                                 â”‚
â”‚  - Metadata: .meta.json                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Components

### 1. CLI (cli.py)
Entry point for document ingestion.

**Responsibilities:**
- Parse command line arguments
- Validate file paths and RAG IDs
- Create job messages
- Push to Redis queue
- Report job status to user

**Commands:**
- `ingest submit` â€” Submit documents for processing
- `ingest status` â€” Check job status
- `ingest reindex` â€” Reindex entire RAG

See: `services/ingest/cli.md`

### 2. Worker (worker.py)
Background service that processes documents.

**Responsibilities:**
- Poll Redis queue for jobs
- Load and parse documents
- Split documents into chunks
- Generate embeddings
- Upsert to Qdrant
- Move files (incoming â†’ processed/failed)
- Update job status
- Handle errors and retries

**Runs as:** Docker service `ingest-worker`

See: `services/ingest/worker.py`

### 3. Queue Contract (queue_contract.md)
Definition of Redis queue format and job lifecycle.

**Defines:**
- Queue key naming
- Job message structure (JSON)
- Job states and transitions
- Error handling

See: `services/ingest/queue_contract.md`

### 4. App (app.py)
Shared utilities for ingest service.

**Provides:**
- Document loaders (PDF, TXT, MD, DOCX)
- Text splitters (chunking)
- Embedding generators (via LangChain)
- File operations (move, delete, archive)
- Logging and error handling

See: `services/ingest/app.py`

---

## Configuration

Ingest behavior is configured in two places:

### 1. Client Configuration (`configs/client/client.yaml`)
Global defaults:
- `paths.sources_root` â€” Root directory for all sources
- `paths.rags_config_dir` â€” Where RAG configs are loaded from

### 2. RAG Configuration (`configs/rags/<rag_id>.yaml`)
Per-RAG settings:
- `sources.directory` â€” Subdirectory for this RAG
- `sources.allowed_extensions` â€” File types to accept
- `sources.max_file_size_mb` â€” Maximum file size
- `sources.auto_reload` â€” Auto-reload on file changes
- `chunking.splitter` â€” Splitting strategy
- `chunking.chunk_size` â€” Characters per chunk
- `chunking.chunk_overlap` â€” Overlap between chunks
- `embeddings.model_name` â€” Model for embeddings
- `embeddings.dimension` â€” Vector dimension

---

## Workflow Example

### Setup
```bash
# 1. Create RAG source directory
mkdir -p data/sources/policies_rag/{incoming,processed,failed}

# 2. Copy documents
cp my_policy.pdf data/sources/policies_rag/incoming/
cp handbook.pdf data/sources/policies_rag/incoming/
```

### Submission
```bash
# 3. Submit for ingestion
python -m services.ingest.cli ingest submit \
  --rag policies_rag \
  --path data/sources/policies_rag/incoming

# Returns: job_id = "rag-policies_rag-1234567890"
```

### Processing
```bash
# Worker automatically processes:
# - Reads my_policy.pdf
# - Splits into chunks
# - Generates embeddings
# - Uploads to Qdrant
# - Moves to processed/
```

### Monitoring
```bash
# 4. Check status
python -m services.ingest.cli ingest status --job rag-policies_rag-1234567890

# Returns: {"status": "done", "chunks": 42, "embeddings": 42}
```

### Query
```bash
# 5. Query is now available
curl http://localhost:8000/api/policies_rag/query \
  -H "Content-Type: application/json" \
  -d '{"query": "What is our PTO policy?"}'
```

---

## File Organization

### Directory Structure
```
services/ingest/
â”œâ”€â”€ README.md                (this file)
â”œâ”€â”€ cli.md                   (CLI documentation)
â”œâ”€â”€ queue_contract.md        (Queue format specification)
â”œâ”€â”€ requirements.txt         (Python dependencies)
â”œâ”€â”€ __init__.py              (Package marker)
â”œâ”€â”€ app.py                   (Shared utilities)
â”œâ”€â”€ cli.py                   (CLI implementation)
â””â”€â”€ worker.py                (Worker implementation)
```

### Data Structure
```
data/sources/
â”œâ”€â”€ policies_rag/
â”‚   â”œâ”€â”€ incoming/            (files to process)
â”‚   â”œâ”€â”€ processed/           (successfully processed)
â”‚   â””â”€â”€ failed/              (failed attempts)
â””â”€â”€ faq_rag/
    â”œâ”€â”€ incoming/
    â”œâ”€â”€ processed/
    â””â”€â”€ failed/
```

---

## Key Concepts

### Job ID Format
```
rag-<rag_id>-<timestamp>-<random>

Example: rag-policies_rag-1704882600-a7b2c3d4
```

- `rag-` â€” Prefix
- `<rag_id>` â€” RAG identifier
- `<timestamp>` â€” Unix timestamp (seconds)
- `<random>` â€” Random 8-character string

### Job States
```
submitted â†’ queued â†’ processing â†’ done/failed
```

- **submitted** â€” Job created by CLI
- **queued** â€” Waiting in Redis queue
- **processing** â€” Worker is processing
- **done** â€” Successfully completed
- **failed** â€” Failed after max retries

### File Transitions
```
incoming/ â†’ processing (in-memory) â†’ processed/ or failed/
```

- Worker reads from `incoming/`
- Processes in memory
- Moves to `processed/` on success
- Moves to `failed/` on error

---

## Error Handling

### Recoverable Errors
Examples: Network timeout, temporary Qdrant unavailable

**Behavior:**
- Retry up to 3 times
- Exponential backoff (1s, 2s, 4s)
- Error logged to worker logs

### Non-Recoverable Errors
Examples: Invalid PDF, unsupported file type, corrupted file

**Behavior:**
- File moved to `failed/`
- Error details written to `.error.json`
- Job marked as failed
- Does NOT retry

### Error Log Format
```json
{
  "job_id": "rag-policies_rag-1704882600-a7b2c3d4",
  "rag_id": "policies_rag",
  "filename": "my_policy.pdf",
  "error": "PDF parsing failed: invalid header",
  "error_type": "ParseError",
  "retry_count": 3,
  "timestamp": "2025-01-10T20:15:30Z",
  "suggestions": [
    "Verify PDF is not corrupted",
    "Try re-exporting PDF from source",
    "Check file permissions"
  ]
}
```

---

## Performance Considerations

### Concurrency
- CLI is synchronous (immediate return)
- Worker is async (multiple jobs simultaneously)
- Queue-based design allows horizontal scaling

### Memory Usage
- Large documents (>50MB) may exhaust memory
- Configure `sources.max_file_size_mb` appropriately
- Monitor worker memory in Docker stats

### Throughput
- Single worker can process ~5-10 docs/minute (depends on size and complexity)
- Add more workers (scale up) for higher throughput
- Queue provides backpressure (jobs wait if worker busy)

### Latency
- CLI submission: <100ms
- Queue wait time: depends on queue length
- Processing: 10s-5min per document (varies)
- Total: typically 1-10 minutes for medium docs

---

## Monitoring & Logging

### CLI Logs
```bash
python -m services.ingest.cli ingest submit ...
# Output: Job submitted: rag-policies_rag-1704882600-a7b2c3d4
#         Check status: ingest status --job <job_id>
```

### Worker Logs
```bash
docker logs raf_chatbot-ingest-worker-1
# Shows:
# - Jobs polled
# - Processing progress
# - Errors and retries
# - File movements
```

### Status Tracking
```bash
python -m services.ingest.cli ingest status --job <job_id>
# Output: 
# Status: done
# Chunks: 42
# Embeddings: 42
# Duration: 3.2 seconds
```

---

## Limitations & Future Improvements

### Current Limitations
- No OCR for scanned PDFs (MVP requirement: clear, born-digital PDFs)
- Single-threaded worker (can add threading)
- No resume on worker restart (jobs re-queued)
- No UI for monitoring

### Planned Improvements
- OCR support for scanned documents
- Multi-threaded worker
- Job persistence across restarts
- Web UI for monitoring
- Batch ingestion with progress bars
- Document versioning (update existing docs)

---

## Dependencies

### Python Packages (see requirements.txt)
- `fastapi` â€” API framework
- `pydantic` â€” Data validation
- `redis` â€” Queue broker
- `qdrant-client` â€” Vector DB client
- `langchain` â€” Loaders and splitters
- `pypdf` â€” PDF parsing
- `python-docx` â€” DOCX parsing

### External Services
- **Redis** â€” Job queue (docker service: `redis`)
- **Qdrant** â€” Vector database (docker service: `qdrant`)

### Docker Services
- `ingest-worker` â€” Worker container (runs continuously)
- See `docker-compose.yml` for configuration

---

## Getting Started

### 1. Review Architecture
Read this file and understand the flow.

### 2. Review CLI Documentation
See: `services/ingest/cli.md`

### 3. Review Queue Contract
Understand message format: `services/ingest/queue_contract.md`

### 4. Review Source Organization
See: `data/sources/README.md`

### 5. Start Services
```bash
make docker-up
```

### 6. Submit Test Document
```bash
echo "This is a test document" > data/sources/example_rag/incoming/test.txt
python -m services.ingest.cli ingest submit --rag example_rag --path data/sources/example_rag/incoming
```

### 7. Check Status
```bash
python -m services.ingest.cli ingest status --job <job_id>
```

---

## Troubleshooting

### "Command not found"
```bash
# Ensure you're in project root
cd G:\zed_projects\raf_chatbot

# Run with python module syntax
python -m services.ingest.cli ingest submit --rag example_rag --path data/sources/example_rag/incoming
```

### "Connection refused" (Redis)
```bash
# Ensure Redis is running
docker ps | grep redis

# If not running:
make docker-up
```

### "No such file or directory"
```bash
# Create source directories first
mkdir -p data/sources/example_rag/{incoming,processed,failed}

# Copy a test file
cp some_file.pdf data/sources/example_rag/incoming/
```

### "Job stuck in processing"
```bash
# Check worker logs
docker logs raf_chatbot-ingest-worker-1

# Worker may have crashed
# Check queue status
python -m services.ingest.cli queue status

# Restart worker
make docker-restart-ingest
```

---

## Questions?

Refer to:
- CLI usage: `services/ingest/cli.md`
- Queue format: `services/ingest/queue_contract.md`
- Source organization: `data/sources/README.md`
- Configuration: `docs/configuration.md`
- Docker setup: `deploy/compose/docker-compose.yml`
```

Now let me create the CLI documentation: